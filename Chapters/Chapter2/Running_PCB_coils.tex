\newpage
\section{Running PCB coils}\footnote{The \textit{"T81-558: Applications of Deep Neural Networks"} course of the Washington University \cite{T81-558} and the \textit{"CS231n: Deep Learning for Computer Vision"}\cite{CS231n} one are used as reference for the presentation of the topic.}
In the vast realm of artificial intelligence, a crucial discipline emerges: machine learning (ML), a transformative approach to programming that defies conventional code-based paradigms. At its essence, machine learning empowers systems to evolve and improve through experiences, learning patterns from data rather than relying on explicit instructions. This paradigm shift opens the door to a new era of problem-solving, where algorithms become adept at making decisions, predictions, and inferences based on the information they ingest.

\begin{figure}[th]
    \centering
    \includegraphics[scale=0.4]{Figures/Chapter2/Timeline-of-AI-to-Deep-Learning.png}
    \caption[Timeline of AI to Deep Learning.]{Timeline of AI toward Deep Learning.}
    \label{fig:TimelineAI}
\end{figure}

At the core of machine learning lies the intricate paradigm between algorithms and data. The learning process begins with a robust dataset, a collection of input features paired with corresponding outcomes. This data serves as the fodder for ML algorithms, mathematical constructs that decode patterns and relationships within the information. As the algorithm processes the data, it continually adjusts its internal parameters to better align its predictions with the ground truth.

Machine learning encompasses various learning paradigms, each tailored to specific challenges. In supervised learning, algorithms learn from labeled data, associating inputs with desired outputs. Unsupervised learning tackles unlabeled data, seeking inherent structures and relationships. Reinforcement learning introduces the element of interaction, where algorithms learn through trial and error, navigating an environment and adapting based on feedback.

As the capabilities of machine learning burgeoned, a more specialized branch emerged: deep learning. This paradigm shift brought about the rise of deep neural networks, inspired by the complexity of the human brain. Deep learning algorithms, structured as multi-layered neural networks, exhibit an unparalleled ability to automatically learn hierarchical representations from data.

Within the deep learning framework, neural networks delve into the intricacies of feature learning. These models, often identified as deep neural networks, boast multiple layers that autonomously extract increasingly complex features. The depth of these networks empowers them to uncover intricate patterns, making them particularly effective in tasks such as image and speech recognition.

The training process in machine learning and deep learning involves an iterative refinement of models. Algorithms, armed with backpropagation mechanisms, fine-tune their internal parameters to minimize the discrepancy between predicted and actual outcomes. This continual optimization results in models that not only perform well on training data but also generalize effectively to new, unseen data.

The applications of machine learning and deep learning span a multitude of domains, reshaping the landscape of technology and problem-solving. From image and speech recognition to natural language processing and autonomous systems, these methodologies have demonstrated unprecedented success. As we delve into the intricacies of machine learning and explore the depths of deep learning, we uncover the transformative power of algorithms that learn, adapt, and redefine the boundaries of artificial intelligence.
% -- Subsection 4.1
\subsection{High current needs}
The neural network is one of the first deep learning model. It emulates how neurons function in the human brain using connected circuits to simulate the intelligent behaviour.\\
Neural networks accept as input a feature vector with fixed length and produces as output a vector of predicted values with fixed length as well. Usually changing the input or output vector length means redesigning the entire structure.\\
The term \textit{"vector"} is usually referred to 1D arrays but with modern neural network it is increasingly common to find multiple dimensions arrays (as I will discuss later with the CNN).\\
The term \textit{"dimension"} can be misleading in neural networks, since, used in sense of the dimension of a vector, it refers to the number of elements present in that vector (for instance, a neural network with ten input neurons has ten dimensions). However, in the case of CNN the input has multiple dimensions, so 2D input to a neural network with 128x128 pixels leads to a configuration of 16,368 input neurons. In the first example the neural network will be defined as 2D NN, in the second one 16,368D.

\begin{figure}[th]
    \centering
    \includegraphics{Figures/Chapter2/NeuralNetwork.jpg}
    \caption[Neural Network]{Neural Network's layer representation.}
    \label{fig:NeuralNetwork}
\end{figure}

% -- Subsection 4.2
\subsection{Costant voltage vs current power supply}
The neural network can functions in regression or classification. In the first case the output is a number predicted on the base of the input data, in the second one the identification of a specific class o category. It is important to note that the output of a regression or two-class classification model is a number (binary for the classification 1 for true value 0 or -1 for false value), but in case of multi-class classification the neural network has an output neuron for each category. 

% -- Subsection 4.3
\subsection{Difference between DC and AC signals}
The artificial neuron receives as input one or more sources from input data or previous layer neurons. It multiplies each of those inputs by a respective weight and sums these multiplications together (sometimes also a bias factor is added). The result is passed to an activation function that determines the output of the neuron.\\
\begin{equation}
    f(x,w) = \phi(\sum_i(w_i\*x_i))
\end{equation}

In the above equation the variables \textit{x} and \textit{w} represent the input and the weights of the neuron respectively, the \(\phi(\cdot)\) the activation function and \textit{f(x,w)} the output of the neuron.

\begin{figure}[th]
    \centering
    \includegraphics[scale=0.6]{Figures/Chapter2/Neuron.jpg}
    \caption[Neuron]{Artificial Neuron representation.}
    \label{fig:Neuron}
\end{figure}

The neurons can be classified in four categories, depending on their position in the architecture:
\begin{itemize}
    \item\textbf{Input Neurons:} each input neuron is mapped to an element in the feature vector.
    \item\textbf{Hidden Neurons:} intermediate neurons responsible of the abstraction of the neural networks to process the input into the output.
    \item\textbf{Output Neurons:} each output neuron calculates one part of the output.
    \item\textbf{Bias Neurons:} introduces an additional learnable parameter that improves the prediction's accuracy by shifting the activation threshold on the activation function.
\end{itemize}

\subsection{AC polarized signals}

\subsubsection{Need for low RMS signals}
Activation functions, or transfer functions, have the role of computing the output of each layer of a neural network. Historically the more common are hyperbolic tangent, sigmoid, or linear activation functions. However, with modern deep learning models, specialized activation functions have been introduced to suit specific applications and tasks:
\begin{itemize}
    \item\textbf{Rectified Linear Unit (ReLU):} use for the output hidden layers.
    \item\textbf{Softmax:} used for the output of classification neural networks.
    \item\textbf{Linear:} used for the output of regression neural networks.
\end{itemize}
In particular ReLU has gained rapid popularity in deep learning due to its ability to yield superior training results. Before the era of deep learning, the sigmoid function was the most prevalent activation function. However, as modern frameworks like PyTorch frequently train neural network using gradient descent optimization, computing partial derivatives of the sigmoid became a computationally challenging operation. The introduction of the Rectified Linear Unit significantly simplified this computation leading to improved performance and faster training.

\begin{figure}[th]
    \centering
    \includegraphics[scale=0.4]{Figures/Chapter2/ActivationFunctions.png}
    \caption[Sigmoid vs. ReLU]{Sigmoid and ReLU activation functions graphic representation.}
    \label{fig:ActivationFunctions}
\end{figure}

%-----------------------------------
%	SUBSECTION 2
%-----------------------------------

%\subsection{Convolutional Neural Network (CNN)}
The Convolutional Neural Network (CNN) is a neural network technology that has deeply impacted the area of computer vision. The original concept of a CNN was introduced by Fukushima in 1980\parencite{fukushima} and subsequent significant advancements were made by LeCun \emph{et al.}\parencite{Lecun}.

\begin{figure}[th]
    \centering
    \includegraphics[scale=0.4]{Figures/Chapter2/CNN.png}
    \caption[Convolution Neural Network]{Convolutional Neural Network visual representation.}

    \label{fig:CNN}
\end{figure}
The CNN, in contrast with most neural networks, has a specific order of the input elements and it is crucial to the training. The inputs are arranged into a grid which represents the input image, the highest-level unit. On the other hand each pixel is the smallest unit within the image and represents a scalar value denoting the intensity or color at a specific location. The images can be colored (expressed on three channels RGB) or grayscale with a single channel.
Due to the amount of data, additional layers are needed to lighten the computation load. The layers works together to extract features from the input data and predict the output. The additional layers are:
\begin{itemize}
    \item\textbf{Convolutional Layers:} apply filters or kernels to perform convolution operations, extracting local features like edges and shapes.
    \item\textbf{Pooling Layers:} reduce the spacial dimensions of feature maps, making the network more robust to scale and orientation variation.
    \item\textbf{Dense Layers:} these layers connect all neurons to every neuron in the previous and subsequent layers, performing high-level feature extraction and decision-making.
    \item\textbf{Flattening Layer:} reshape the output from convolutional layers to 1D vector, allowing it to connect to fully connected (dense) layers.
\end{itemize}

%\subsubsection{Training and Testing Processes}
The training process begins with the initialization of the network's weight and biases; usually these parameters are set to small random values.\\
The input is then fed through the network, the data propagates through each layer and predictions are produced. A loss function is used to quantify the error between the predicted and the ground truth values. The choice of the loss function depends on the specific task, the most common are MSE for regression and cross-entropy for classification. The backpropagation algorithm is employed to compute the gradients of the loss with respect to the network's parameters (weights and biases).\\
This process is essentially the chain rule from calculus, which calculates how small changes in each parameter affect the loss. Using the gradients computed during backpropagation, the network's weights and biases are updated through an optimization algorithm.

The goal is to adjust the parameters in a way that minimizes the loss function. The process is then iterated over the entire training dataset with a process called epoch. Multiple epochs are typically performed to improve the model's performance.

Periodically, the model's performance is evaluated on a separated validation dataset that the network has not seen during training. This method helps monitor the model's generalization capabilities.

After training and validation, the model is tested on a completely unseen test dataset to evaluate its performance on new, independent data.